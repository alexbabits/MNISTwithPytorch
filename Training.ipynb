{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install --upgrade torch \n",
    "%pip install torchvision\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from PIL import Image (???)\n",
    "#from torch.utils.data import Dataset (for custom datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "num_classes = 10\n",
    "input_shape = (1, 28, 28)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=676, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(4 * 13 * 13, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 4 * 13 * 13)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302444\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.258052\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.678626\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.614861\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.587631\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.454680\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.832637\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.672267\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.447332\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.476280\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.516257\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.254317\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.218447\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.343588\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.426853\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.657658\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.229491\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.220436\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.449250\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 9260/10000 (92.60%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.472686\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.376004\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.454856\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.369300\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.469675\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.432684\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.381918\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.855087\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.145772\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.380418\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.507842\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.312368\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.286997\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.387860\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.248187\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.504666\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.318101\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.166590\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.229861\n",
      "\n",
      "Test set: Average loss: 0.0073, Accuracy: 9378/10000 (93.78%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.255470\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.281807\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.496656\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.486385\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.710249\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.084181\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.383403\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.429773\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.463449\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.259584\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.339853\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.123301\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.055062\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.386877\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.485313\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.356996\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.375210\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.386878\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.261952\n",
      "\n",
      "Test set: Average loss: 0.0068, Accuracy: 9404/10000 (94.04%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.267249\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.116494\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.248834\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.624199\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.151812\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.398773\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.350576\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.330494\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.247213\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.351644\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.299493\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.794258\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.905624\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.734544\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.312029\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.708172\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.174080\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.367876\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.368325\n",
      "\n",
      "Test set: Average loss: 0.0063, Accuracy: 9443/10000 (94.43%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.140740\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.155904\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.336785\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.242050\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.369862\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.453846\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.249483\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.409388\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.570478\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.313927\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.424221\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.546582\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.328365\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.130954\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.352672\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.253951\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.403776\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.329003\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.388453\n",
      "\n",
      "Test set: Average loss: 0.0061, Accuracy: 9486/10000 (94.86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the trained model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
